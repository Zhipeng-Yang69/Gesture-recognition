{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import deque, Counter\n",
    "#the original code is from the paper I replicate, I improved the code , added functions and some features to increase the accuracy for gesture recognition.\n",
    "# Load templates from a directory\n",
    "#template_dir = \"C:/Users/admin/Desktop/computer_vision/Template\"\n",
    "template_dir = \"C:/Users/admin/Desktop/computer_vision/signLanguage_Templates\"\n",
    "templates = []\n",
    "template_names = []\n",
    "SMOOTHING_WINDOW = 7\n",
    "\n",
    "def load_templates(rf = 0.3):\n",
    "    #load templates\n",
    "    for template_file in os.listdir(template_dir):\n",
    "        template_path = os.path.join(template_dir, template_file)\n",
    "        template = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)  # Read the template in grayscale\n",
    "        template = cv2.resize(template, None, fx=rf, fy=rf)\n",
    "        template = cv2.flip(template, 1)\n",
    "        #add Gaussian Blur\n",
    "        template = cv2.GaussianBlur(template, (5, 5), 0)\n",
    "        # add Histogram Equalization,Fix lighting & contrast differences\n",
    "        template = cv2.equalizeHist(template)\n",
    "        templates.append(template)\n",
    "        template_names.append(os.path.splitext(template_file)[0])\n",
    "\n",
    "def draw_ROI(background, original_image, original_frame, prev_cX):\n",
    "    #difference image\n",
    "    diff = cv2.absdiff(background, original_image)\n",
    "    diff = cv2.GaussianBlur(diff, (5, 5), 0)\n",
    "    #thresholded image\n",
    "    _, thresholded_diff = cv2.threshold(diff, 45, 255, cv2.THRESH_BINARY)\n",
    "    #Morphological transformations :smooths contours, breaks thin connections, and removes small objects \n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    #remove small dots\n",
    "    thresholded_diff = cv2.morphologyEx(\n",
    "        thresholded_diff,\n",
    "        cv2.MORPH_OPEN,\n",
    "        kernel\n",
    "    )\n",
    "    #fill tiny black gaps and smooths the dots\n",
    "    thresholded_diff = cv2.morphologyEx(thresholded_diff, cv2.MORPH_CLOSE, kernel)\n",
    "    #contours\n",
    "    contours, _ = cv2.findContours(thresholded_diff, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    ismoving = False\n",
    "    contours = [c for c in contours if cv2.contourArea(c) > 800]\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        \n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "        moments = cv2.moments(largest_contour)\n",
    "\n",
    "        cv2.rectangle(original_frame, (original_frame.shape[1]-300 + x, y), (original_frame.shape[1]-300 + x + w, y + h), (255,0,0), 2)            \n",
    "        \n",
    "        if moments[\"m00\"]:\n",
    "            centroid_x = int(moments[\"m10\"] / moments[\"m00\"])\n",
    "            centroid_y = int(moments[\"m01\"] / moments[\"m00\"])\n",
    "                        # Check if the centroid has moved a lot horizontally\n",
    "            if abs(centroid_x - prev_cX) > 15 and moments[\"m00\"] != 0:\n",
    "                prev_cX= centroid_x\n",
    "                ismoving =  True\n",
    "\n",
    "            original_frame = cv2.circle(original_frame, (original_frame.shape[1]-300 +centroid_x, centroid_y), 5, 128, -1)\n",
    "            original_frame = cv2.putText(original_frame, f'Centroid', (original_frame.shape[1]-300 +centroid_x, centroid_y), cv2.FONT_HERSHEY_PLAIN, 1, (255, 0, 0), 2)\n",
    "\n",
    "    return original_frame, thresholded_diff, ismoving, prev_cX\n",
    "#normalizes an image so that its pixel values are comparable across frames and templates.\n",
    "def normalize(img):\n",
    "    img = img.astype(np.float32)\n",
    "    if img.std() < 1e-5:\n",
    "        return img\n",
    "    return (img - img.mean()) / img.std()\n",
    "\n",
    "def classify(original_image, original_frame, ismoving):\n",
    "    #temporal smoothing memory,in order to reduce the noise,and creat history to track the history predicts\n",
    "    if not hasattr(classify, \"history\"):\n",
    "        classify.history = deque(maxlen=SMOOTHING_WINDOW)\n",
    "    # Initialize variables to keep track of the best match\n",
    "    best_match_value = -1\n",
    "    best_template_index = -1\n",
    "    best_scale_factor = 1.0\n",
    "\n",
    "    # Iterate through templates\n",
    "    for i, template in enumerate(templates):\n",
    "        # Initialize variables for the current template\n",
    "        template_best_match_value = -1\n",
    "        #template_best_scale_factor = 1.0\n",
    "        template=normalize(template)\n",
    "        # Iterate through different scales of the image\n",
    "        for scale_factor in np.linspace(0.1, 1.0, 10):\n",
    "            scaled_image = cv2.resize(original_image, None, fx=scale_factor, fy=scale_factor)\n",
    "\n",
    "            scaled_image = normalize(scaled_image)\n",
    "            #template=normalize(template)\n",
    "\n",
    "            if scaled_image.shape[0]<template.shape[0] or scaled_image.shape[1]<template.shape[1]:\n",
    "                continue\n",
    "            result = cv2.matchTemplate(scaled_image, template, cv2.TM_CCOEFF_NORMED)\n",
    "            _, max_val, _, _ = cv2.minMaxLoc(result)\n",
    "\n",
    "            # Update the best match information for the current template\n",
    "            if max_val > template_best_match_value:\n",
    "                template_best_match_value = max_val\n",
    "                template_best_scale_factor = scale_factor\n",
    "\n",
    "        # Update the overall best match information\n",
    "        if template_best_match_value > best_match_value:\n",
    "            best_match_value = template_best_match_value\n",
    "            best_template_index = i\n",
    "            best_scale_factor = template_best_scale_factor\n",
    "    #raw prediction\n",
    "    raw_label=None\n",
    "\n",
    "    corr_threshold = 0.8\n",
    "    # Draw a rectangle around the matched template\n",
    "    if best_template_index != -1 and best_match_value>corr_threshold:\n",
    "        # Display the class label\n",
    "        raw_label = template_names[best_template_index].split('_')[0]\n",
    "        #update the history\n",
    "    \n",
    "    if raw_label is not None:\n",
    "        classify.history.append(raw_label)\n",
    "        \n",
    "        #stable smoothed label\n",
    "    stable = None\n",
    "    if len(classify.history) > 0:\n",
    "        stable = Counter(classify.history).most_common(1)[0][0]\n",
    "    if stable is not None:\n",
    "        #that is for rock and paper motion detection and replicate the original paper.\n",
    "        if ismoving:\n",
    "            if stable == \"rock\":\n",
    "                cv2.putText(original_frame, f\"Don't hit me with that rock!\", (10, 70), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 2)\n",
    "            elif stable == \"paper\":\n",
    "                cv2.putText(original_frame, f\"Bye!\", (10, 70), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 2)\n",
    "\n",
    "        cv2.putText(original_frame, f'Class: {stable}', (10, 30), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 0), 2)\n",
    "        cv2.putText(original_frame, f'corr: {best_match_value}', (10, 50), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 0), 2)\n",
    "    else:\n",
    "        cv2.putText(original_frame, f'No Hand Detected', (10, 30), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 0), 2)\n",
    "    return original_frame\n",
    "\n",
    "def main():\n",
    "    load_templates()\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Couldn't open the webcam.\")\n",
    "        return\n",
    "    ret, background = cap.read()\n",
    "    prev_cX = 0\n",
    "    #set background\n",
    "    \n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        # Capture frame from webcam\n",
    "        ret, original_frame = cap.read()\n",
    "        original_frame = cv2.flip(original_frame, 1)\n",
    "        #in case, recapture includes the centroid frame\n",
    "        clean_frame = original_frame.copy()  \n",
    "        frame_count += 1\n",
    "        if not ret:\n",
    "            print(\"Error: Couldn't read a frame from the webcam.\")\n",
    "            break\n",
    "        set_background_after = 60\n",
    "        if frame_count<set_background_after:\n",
    "            continue\n",
    "        if frame_count==set_background_after:\n",
    "            #background = cv2.cvtColor(original_frame, cv2.COLOR_BGR2GRAY)[:300,-300:]\n",
    "            bg = cv2.cvtColor(original_frame, cv2.COLOR_BGR2GRAY)[:300, -300:]\n",
    "            bg = cv2.GaussianBlur(bg, (5, 5), 0)\n",
    "            background = cv2.equalizeHist(bg)\n",
    "        #Region to consider\n",
    "        roi = cv2.cvtColor(original_frame, cv2.COLOR_BGR2GRAY)[:300,-300:]\n",
    "        #Apply Gaussian Blur and Histogram Equalization.\n",
    "        roi = cv2.GaussianBlur(roi, (5, 5), 0)\n",
    "        roi = cv2.equalizeHist(roi)\n",
    "\n",
    "        original_frame, thresholded_diff, is_moving, prev_cX= draw_ROI(background, roi,original_frame, prev_cX)\n",
    "        #clean the history predicts if there is no hand moving\n",
    "        if not is_moving and np.count_nonzero(thresholded_diff) < 500:\n",
    "             if hasattr(classify, \"history\"):\n",
    "                 classify.history.clear()\n",
    "        original_frame = classify(roi, original_frame, is_moving)\n",
    "        \n",
    "        #original_frame = classify(roi, original_frame, is_moving)\n",
    "        cv2.rectangle(original_frame, (original_frame.shape[1]-300, 0), (original_frame.shape[1], 300), (0,255,0), 2)\n",
    "        #add note for recapture\n",
    "        cv2.putText(original_frame, \"Press 'b' to recapture background\", (10, 90),cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0), 2)\n",
    "        cv2.imshow('Template Matching', original_frame)\n",
    "        cv2.imshow('threshold', thresholded_diff)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        # press 'b' to re-capture background\n",
    "        if key == ord('b'):\n",
    "            bg = cv2.cvtColor( clean_frame , cv2.COLOR_BGR2GRAY)[:300, -300:]\n",
    "            bg = cv2.GaussianBlur(bg, (5, 5), 0)\n",
    "            background = cv2.equalizeHist(bg)\n",
    "            #print(\"Background re-captured!\")\n",
    "            \n",
    "            # clear temporal smoothing history\n",
    "            if hasattr(classify, \"history\"):\n",
    "                classify.history.clear()\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "      \n",
    "        if key==ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the webcam and close all windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
